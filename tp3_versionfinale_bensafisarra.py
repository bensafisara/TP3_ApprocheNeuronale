# -*- coding: utf-8 -*-
"""TP3_versionFinale_BensafiSarra.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19o6RBBRfkSNuAjrjFZZPPoNCdoWSZ9ce

Bensafi Sarra
"""

from numpy import linalg as LA
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import itertools
import re
import numpy as np
import random
import math
from scipy import linalg

"""Fonctions Utiles"""

def initialisationHebb(X,N,etiq):
    
    #Step 1 mettre en place les weights
    W_hebb = np.zeros((N))
    
   

    #Step 3  mettre en place pred
    
    pred=etiq

    for i in range(len(X)):
     
      #Step 4 w(nouveau) = w(vieux) + xi*yi  
      W_hebb=W_hebb+(X[i]*pred[i])

    
    W_hebb=W_hebb/ LA.norm(W_hebb)
  
     
    return W_hebb
########################################
def Stabilite(etiq,W,X):
    
    enum=etiq*np.dot(X,W)
    return enum/linalg.norm(W)
########################################
'''L'erreur de généralisation = l'erreur sur de nouvelles données
    on doit calculer combier y'a t'il de fautes avant
'''
def Error(Etiq , predicted):

  return (Etiq != predicted).sum()

def generalisation(NBtot,NbErr) :
    NbBienClasse=NBtot-NbErr
    return NbBienClasse/NBtot
########################################

def defineTau(X,w):
  tau=[]
  X = np.atleast_2d(X)
  for x in X:
       
       if np.dot(w,x)<=0:
           tau.append(-1)
           
       else:
           tau.append(1)
           
       
  #plt.show
  return tau
########################################
def Stabilite(etiq,W,X):
    
    enum=etiq*np.dot(X,W)
    return enum/linalg.norm(W)
########################################
def plotstab(s):
    plt.hist(s, range=(-0.5, 0.7), bins=10, facecolor='red', alpha=0.5,edgecolor='blue')
    plt.show()

"""**PARTIE** 1"""

def Minimerror(X,etiq,W,iterations):
  
  #Parameters
  iterats=0
  betaplus=0.01
  delta=0.01
  alpha=0.01
  
  while iterats<=iterations :
      dW=0
      Wnorm = LA.norm(W)
      for i, (Xi, etiqi) in enumerate(zip(X, etiq)):
              Xi = np.atleast_2d(Xi)
              stab= etiqi * np.dot(Xi, W) / Wnorm 

              dW+=     Xi/      (np.cosh(betaplus*stab/2)**2)*etiqi
              
      dW = - dW * betaplus / 4
      W -=alpha* dW[0]
      betaplus=betaplus+delta
      iterats=iterats+1
  
  return W

'''ET'''
#X et Y
X_= np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])
X_= np.insert(X_,0,1,axis=1)
etiq = np.array([[-1], [-1], [-1], [1]])
print(etiq.shape)


N=len(X_[0])

#Weights
W_=initialisationHebb(X_,N,etiq)
W_=W_

Weights_ET=Minimerror(X_,etiq,W_,100)
print(Weights_ET)

etiq_et_MinimError=defineTau(X_,Weights_ET)
print(etiq_et_MinimError)

#Compter les erreurs gen et app
NbErr = Error(etiq.flatten(),etiq_et_MinimError)

Eg=generalisation(4,NbErr)
print("Erreur de généralisation",Eg)
print("Erreur d'apprentissage",NbErr)



#Calculer stabilité
Stab_et=Stabilite(etiq,Weights_ET,X_)
print("Stabilité")
print(Stab_et)

print("Plot de Stabilité")
plotstab(Stab_et)

'''ou'''
#X et Y
# construct the OR dataset
X_= np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])
X_= np.insert(X_,0,1,axis=1)
etiq_ou = np.array([[-1], [1], [1], [1]])
N=len(X_[0])

#Weights
W_=initialisationHebb(X_,N,etiq_ou)
W_=W_


W_=Minimerror(X_,etiq_ou,W_,1000)
print(W_)
etiqMinimerror = defineTau(X_,W_)


#Compter les erreurs gen et app
NbErr = Error(etiq_ou.flatten(),etiqMinimerror)

Eg=generalisation(4,NbErr)
print("Erreur de généralisation",Eg)
print("Erreur d'apprentissage",NbErr)




#Calculer stabilité
Stab_ou=Stabilite(etiq,W_,X_)
print("Stabilité")
print(Stab_ou)



print("Plot de Stabilité")
plotstab(Stab_ou)

#Sonar
N = 60 #les colonnes
P = 104 #les lignes
etiq = np.loadtxt('/content/drive/MyDrive/M2Avignon/ApprocheNeuronales/Donnees/etiq_test.txt',dtype='int')
etiq=etiq.reshape((104, 1))
etiq=np.array(etiq,dtype=int)

X_ = np.loadtxt("/content/drive/MyDrive/M2Avignon/ApprocheNeuronales/Donnees/test.txt")

ones = np.ones((len(X_),1))
X_ = np.append(ones,X_,axis=1)
X_=np.array(X_,dtype=float)

N=len(X_[0])
print(N)


#Weights
W_=initialisationHebb(X_,N,etiq)
W_=W_

W_=Minimerror(X_,etiq,W_,8000)

etiqMinimerror=defineTau(X_,W_)



#Compter les erreurs gen et app
NbErr = Error(etiq.flatten(),etiqMinimerror)
Eg=generalisation(P,NbErr)
print("Erreur de généralisation",Eg)
print("Erreur d'apprentissage",NbErr)


print("")
print("Weights sonar")
print(W_)



#Calculer stabilité
Stab_sonar=Stabilite(etiq,W_,X_)
print("Stabilité")
print(Stab_sonar)


print("sonar")

def plotstab(s):
    plt.hist(s, range=(-0.5, 0.7), bins=10, facecolor='red', alpha=0.5,edgecolor='blue')
    plt.show()
print("Plot de Stabilité")
plotstab(Stab_sonar)

"""**PARTIE** 2"""

def Minimerror_2(X,etiq,W,iterations):
  
  #Parameters
  iterats=0
  betaplus=0.01
  betamoins=0.001 #(6/0.01)
  delta=0.01
  alpha=0.01
  
  while iterats<=iterations :
      dWp=0
      dWn=0
      
      Wnorm = LA.norm(W)
      
      for i, (Xi, etiqi) in enumerate(zip(X, etiq)):
              Xi = np.atleast_2d(Xi)
              stab= etiqi * np.dot(Xi, W) / Wnorm 
              
              
              #selon la stabilité
              if stab>0:
                  dWp+=     Xi/      (np.cosh(betaplus*stab/2)**2)*etiq[i]
              else :
                   dWn+=     Xi/      (np.cosh(betamoins*stab/2)**2)*etiq[i]
              
              
      dW = - np.add(dWp,dWn) * betaplus / 4
      W -=alpha* dW[0]
      betaplus=betaplus+delta
      betamoins=betamoins+delta
      iterats=iterats+1
  
  return W

"""Et"""

'''ET'''
#X et Y
X_= np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])
X_= np.insert(X_,0,1,axis=1)
etiq = np.array([[-1], [-1], [-1], [1]])
print(etiq.shape)


N=len(X_[0])

#Weights
W_=initialisationHebb(X_,N,etiq)
W_=W_
print(W_)



#Trouver etiquetteprédite
Weights=Minimerror_2(X_,etiq,W_,1000)
etiq_et_MinimError2=defineTau(X_,Weights)
print(etiq_et_MinimError2)

#Compter les erreurs gen et app
NbErr = Error(etiq.flatten(),etiq_et_MinimError2)

Eg=generalisation(P,NbErr)
print("Erreur de généralisation",Eg)
print("Erreur d'apprentissage",NbErr)


#Calculer stabilité
Stab_ET=Stabilite(etiq,Weights,X_)
print("Stabilité")
print(Stab_ET)



print("Plot de Stabilité")
plotstab(Stab_ET)

"""ou"""

'''ou'''
#X et Y
# construct the OR dataset
X_= np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])
X_= np.insert(X_,0,1,axis=1)
etiq_ou = np.array([[-1], [1], [1], [1]])
N=len(X_[0])

#Weights
W_=initialisationHebb(X_,N,etiq)
W_=W_


#Trouver etiquetteprédite
Weights=Minimerror_2(X_,etiq,W_,1000)
etiq_ou_MinimError2=defineTau(X_,Weights)
print(etiq_ou_MinimError2)

#Compter les erreurs gen et app
NbErr = Error(etiq.flatten(),etiq_ou_MinimError2)

Eg=generalisation(P,NbErr)
print("Erreur de généralisation",Eg)
print("Erreur d'apprentissage",NbErr)




#Calculer stabilité
Stab_ou=Stabilite(etiq_ou,Weights,X_)
print("Stabilité")
print(Stab_ou)



print("Plot de Stabilité")
plotstab(Stab_ou)

"""Sonar"""

#Les labels 
etiq_sonar = np.loadtxt('/content/drive/MyDrive/M2Avignon/ApprocheNeuronales/Donnees/etiq_test.txt',dtype='int')
etiq_sonar=etiq_sonar.reshape((104, 1))
etiq_sonar=np.array(etiq_sonar,dtype=int)

#Données X
X_ = np.loadtxt("/content/drive/MyDrive/M2Avignon/ApprocheNeuronales/Donnees/test.txt")
ones = np.ones((len(X_),1))
X_ = np.append(ones,X_,axis=1)
X_=np.array(X_,dtype=float)

#N
N=len(X_[0])
print(N)


#Weights
W_=initialisationHebb(X_,N,etiq_sonar)
W_=W_

Weights=Minimerror_2(X_,etiq_sonar,W_,8000)



#Trouver etiquetteprédite
etiq_sonar_predicted_MinimError2=defineTau(X_,Weights)
etiq_sonar_predicted_MinimError2=np.array(etiq_sonar_predicted_MinimError2,dtype=int)


#Compter les erreurs gen et app
NbErr = Error(etiq_sonar.flatten(),etiq_sonar_predicted_MinimError2)
print(NbErr)
Eg=generalisation(P,NbErr)
print("Erreur de généralisation",Eg)
print("Erreur d'apprentissage",NbErr)

#les poids
print(Weights)

#Calculer stabilité
Stab_sonar=Stabilite(etiq,Weights,X_)
print("Stabilité")
print(Stab_sonar)


print("sonar")

def plotstab(s):
    plt.hist(s, range=(-0.5, 0.7), bins=10, facecolor='red', alpha=0.5,edgecolor='blue')
    plt.show()
print("Plot de Stabilité")
plotstab(Stab_sonar)